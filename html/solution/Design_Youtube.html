


<html>
<body>

<a href="https://www.educative.io/courses/grokking-the-system-design-interview/xV26VjZ7yMl">Groking system interview Answer</a>

<pre><code>

实用范围：　Streaming service: Youtube, Netflix, Spotify

Step1: 

Assumption: each minute user uploads 500 hours worth video

Storage: each minute takes 50MB storage, 500 * 60 * 50MB = 1500GB / minute = 25GB/s

bandwidth: upload per minute video takes 10MB bandwidth, 500 * 60 * 10MB = 300GB/minute = 5GB/s 



Step2: System API,
(1)UploadVideo(API_dev_key, title, description, tags[], category, recording_detail, video_content);

a. A successful upload will return HTTP 202 (request accepted), We can also expose a queryable API to let users know the current status of their uploaded video.
b. once the video encoding is completed the user is notified through email with a link to access the video. 


(2)SearchVideo(API_dev_key, keyword, Max_numbers_Items_to_return, page Token)

return Json that contains list of items, where each item consists video title, thumbnail, creation time, author.

(3)StreamVideo(API_dev_key, videoid, offset, device)

return the video stream starting from offset.


Step 3: Service Architecture
<img src="../../img/youtube.png" width="800px" height="800px">

               Web server  ->  App server -> distribute File System (S3)  for large file like(log, video, image)

                                    |
                              metadata Database





Step 4: DB Schema/partition

Video metadata table:
Video Id      PK 
title         
description   
video path    
thumbnailpath 
size         
user          fk
like 
dislike
total view    


User table 
id 
name
email
password 


Comment table: 
comment_id   pk 
video_id     fk 
userid       fk 
content      
timestamp    



Sharding video metadata table:
1. Shard by user ID: drawback: popular user. QPS ( too many query), storage ( too many videos).
2. Shard by video ID: Zookeeper generates a global unique video id, hash to one random server.
                      The draw back is 
                      1.you need to have a aggregator server, if you want to get all videos of a user 
                      2. popular video. high qps query to that shard, this problem still exists          
           







Step 5: scale

Cache:

Metadata will be cached in either app server or seperate server using memcached or Radis.
App server hit cache first, if there is a cache miss, it hits DB.

Eviction policy?
LRU

more efficient? 
80-20 rule 




CDN:
Geographically closer to user, most likely cache the video in memory.


</code></pre>

s
</body>



</html>
