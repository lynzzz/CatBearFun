<html>
<body>



<pre><code>

  <li><a href="https://www.educative.io/courses/grokking-the-system-design-interview/m2yDVZnQ8lG">grokking system design solution</a>  </li>
  <li><a href="https://www.acecodeinterview.com/intro/instagram.html#%E8%B5%84%E6%BA%90%E4%BC%B0%E7%AE%97-back-of-the-envelope-calculation-optional">Ace system design interview(Who claims to be Interviewer from FLAG)</a>  </li>


1. Storage

Storage for photo:
say everyday 2m photos created and average photo size 200kb, total storage is 2m * 200kB = 400 * 10^9Byte = 400GB.
one day we need 400GB disk, and one month, we need 12TB disk, so photos cannot be stored in one machine, what we need is
distributed file storage such as S3.

storeage for table
image table:
id 4byte + user id 4byte + title 50byte + createdAt 50 byte + image path = 256Byte = 364 Byte
364Byte * 2m = 0.7G per day, 21GB per month. 240GB per year.

user table:
id 4Byte + name 20byte + email 50byte + created At 4Byte + last login 4Byte = 82byte
say there is 500M user. total size = 82 Byte * 500M = 40GB

Friendship table:
id 4byte, from 4 byte, to 4 byte, total 12byte
500M users, each user follow 100 user, total = 500M * 100 * 12byte = 0.6TB.

QPS:
say there are 500M user, 1M daily active user, each user does 10 read operation per day.
say there are 500M daily active user, each user does 1 write operation per day.

Read QPS = 1M * 10/86400 = 100.
Write QPS = 10

Bandwidth:
bandwidth = QPS * average size/per request or response
if average size per response 2M

outgoing bandwidth = 100 * 2M = 200M/s

Table schema:
User table
id          int PK
name        varchar(25)
email       varchar(30)
updatedAt   timestamp
createdAt   timestamp

photo table
id        int  PK
userId    int  FK
title     varchar(50)
createdAt timeStamp
ImagePath varChar(50)


frinedship table
id    int PK
from  int
to    int

Generate News feed for sam whose user id is 1

select photo.title, photo.user_id, photo.createdAt from
(select * from friendship where from_user = 1) as f
left join photo
on f.to_user = photo.user_id
order by photo.createdAt;




// Sql statment to creat table and insert value
 create database ins  // create database
 use ins// use database

 // create user table
create table user(id int not null auto_increment, name varchar(50) not null, email varchar(50), primary key (id));
 // insert value;
 insert into user (name, email) values ("Lyn", "lzengzeng22@gmail.com");
insert into user (name, email) values ("Mark", "mark@gmail.com");
insert into user (name, email) values ("Jay", "mark@gmail.com");
insert into user (name, email) values ("NanXia", "Nan@gmail.com");
insert into user (name, email) values ("Jing", "Jing@gmail.com");

// create friendship table;
create table friendship(id int not null auto_increment, from_user int not null, to_user int not null, primary key (id));
insert into friendship (from_user, to_user) values (1, 2);
insert into friendship (from_user, to_user) values (1, 3);
insert into friendship (from_user, to_user) values (1, 3);
insert into friendship (from_user, to_user) values (2, 5);
insert into friendship (from_user, to_user) values (2, 3);
insert into friendship (from_user, to_user) values (4, 3);


// create photo table
create table photo(id int not null auto_increment primary key, user_id int not null, title varchar(100) not null, image_path varchar(50) not null, createdAt TIMESTAMP DEFAULT CURRENT_TIMESTAMP );
insert into photo (user_id, title, image_path) values (3, "Japan photo", "Azure/Jay");
insert into photo (user_id, title, image_path) values (2, "California San Diego photo", "Azure/Mark");
insert into photo (user_id, title, image_path) values (3, "Cancun trip", "Azure/Jay");




// Query to get user 1 的 News feed

select photo.title, photo.user_id, photo.createdAt from
(select * from friendship where from_user = 1) as f
left join photo
on f.to_user = photo.user_id
order by photo.createdAt;

此处还可以用NOSQL DB 来存用户和照片的关系, 哪个用户拥有哪些照片, 这样的话就不用像上面那样sql语句做join between Photo table和user table做Join
key: userID
value: List of photo ID the user owns。
2->{100,101}
3->{102,103}

Pull mode:
No need to create feed table.
1. Get the users that I am following.
select to_user from friendship where from_user = 1;

2. Left join with photo table, and sort by creation date.
select photo.title, photo.user_id, photo.createdAt from
(select * from friendship where from_user = 1) as f
left join photo
on f.to_user = photo.user_id
order by photo.createdAt;
<img src="../../img/push.png" width="800px" height="800px">


Push mode:
When someone publishes a photo, it is going to fan out
the message to all users that are following me. How to do it?

1. Get user's followers
select from_user from friendship where to = 1.

2. create a feed table for user. add an entry to feed table for all follower.

Schema;
feedtable
id int not null auto_increment primary key
userId
photoId

Question:
爱思系统设计说，这个表里一定要加creation time用来排序，但我认为这个表里产生的photo id和
最终要和photo table做join,photo table里面有creation time, 那个时候可以排序，为撒feedtable还要存一次？

回答说：
Feed table先按照creation timestamp sort, 取前N位，在和photo table做 join 比
Feed table直接和photo table做Join, 在sort, 在取前N位要快。

更快的方式是de-normalize (小表变大表, 把Photo table的column加进来到feedtable里)， 这样就不用join了。
pro: 不用Join, latency低
Con: 需要占用更多的存储空间。

Feedtable
feed_id
user_id
photo_id
title     varchar(50)
createdAt timeStamp
ImagePath varChar(50)

Sql statement:
select * from feed where user_id = 1
order by createdAt DESC
limit 40


sql statement to create table:
create table feed(id int not null auto_increment, userId int not null, photoId int not null, primary key (id));

Example:
When someone uploads a photo, say Jay uploads a photo
insert into photo (user_id, title, image_path) values (3, "Japan photo", "Azure/Jay"); it generates photo ID 1

It is going to fan out the photo ID 1 to Jay's followers feedtable
select from_user from friendship where to_user = 3;  result is 1,2,4
in this case, which are me, mark and Nan.

insert into feed(userId, photoId) values(1, 1);
insert into feed(userId, photoId) values(2, 1);
insert into feed(userId, photoId) values(4, 1);

and then mark uploads the picture
insert into photo (user_id, title, image_path) values (2, "California San Diego photo", "Azure/Mark"); the crosponding photo id is 4
It is going to fanout the photoID to Mark's follower's news feedtable,
select from_user from friendship where to_user = 2;  result is 1, which is Lyn

need to add this message to lyn's feed table/
insert into feed(userId, photoId) values(1, 4);

Then, you go to Lyn's news feed, just do a join between news table and photo Table
select title, image_path, createdAt, photo.user_id from
(select photoID from feed where userId = 1) as f
left join photo
on f.photoId = photo.id
order by photo.createdAt desc;


// Optimization to create index on photo id and photo creation time.
create index idx_on_photo_id_and_creationTime on photo(id, createdAt);

Push Mode:
pro: latency is low, since you have a table store all the feed of a user.
cons: Fan out for celebrity, it takes time and resources(async workers).

How to solve celebrity problem using push mode.
Hybrid mode: Push for regular user and pull for Celebrity.
How ?

<img src="../../img/hybrid.png" width="800px" height="800px">

Create a seperate celebrity photo table for celebrity and do not fanout the photo id to feed table.
When one user requests feed view, it gets feed from feed table and then get the users that he is following and join with celebrity photo table,
Those two components merge together.


Can we define a boundry for celebrity?
No, because number of fans are changing and for those that are on the line, Fan out sometimes happen, sometimes doesn't happen, which causes
problems.

How to handle the user that becomes a celebrity very fast before the system recginized it as a celebrity?
backfill his photo entry from photo table to celebrity photo table, and delete his fan-out feed in feed table.




2. reliability and Redundency
  1. Problem with one single storage server: Single point failure
  2. Solution: creating replica,
  3. when one server fails, the trafic will be routed to the remaining ones, which is called fail-over



3.Web server optimization:
  Knowledge: Web server has connection limit, which I think is QPS limit, typically one webserver can handle 1000 QPS.

  Write goes to disk, it is slow. "read" cannot be serverd if web server is busy with all write requests.
  solution: Have dedicated servers for read and different servers for write that update doesn't hog the web server.


4. Data Partition: (Horizontal partition, 横着分)
  Partition phto table:
  Approach 1: partition by user ID. say you have 10 servers, server number can be obtained by user_id%10. that way, all photos of a user
              are saved in one partition. In partition photo table, primary photo id will be different from original one and is auto-incremented.

          for example, partition the photo table by user ID, userID%2
          original photo table:
          photoID     userId     content
             1           201      dog
             2           201      cat
             3           200      tree
             4           200      people
             5           201      male
             6           202      female

          partition table 1                                 partition table 2
          photoID        userID  content                    photoID        userID    content
             1            200      tree                       1               201      dog
             2            200      people                     2               201      cat
             3            202      female                     3               201      male


  Drawback: a. QPS: hot user, lady gaga, a lot of user see her picture, QPS load of that partition is high.
            b. Storage: if a user has too many pictures, the distribution is not uniform.
            c. Single point failure: if this partition is down, all photos of some user will be unavailable.

  Data Migration: old data, each entry in photo table has user_id, it maps to a partition, that partition auto increment and add the new entry in.
                  new generated data: new data also has user_id, that maps to a partition, do auto_increment in that shard.
                  example: user id 700 content aloha, it maps to shard 1.
                  photoId    userID  content
                     4        700     aloha.



   Approach II: partition by photoID:
           old photo entry can be mapped to the crosponding shard, but the challenge is new photo doesn't come with an photo ID, you don't know which shard it maps to. We need to have a dedicated database generating global photo id,
           we can set up a database table to generate auto-incremented photo ID.

           And then you map global photo id to a shard, add the entry into the shard key.
           The shard table should not use auto-incremented ID as primary ID, it should use global photo id as primary key.

               global ID table
           Image ID:
           1
           2
           3
           4
           5
           6

           parition 1                                            partition 2
           photo ID   userID    content              photo ID       user ID       content
            1          201         dog                  2             201          cat
            3          200         tree                 4             200          table
            5          201         male                 6             202          female

  Follow up Question: Single point failure on this key-generation db
  1. Replica is not the solution, since there is no guanrantee two dbs are synced at only time. if one db is down, other db may or may not be synced.
     if one number is wrong, user lose data.
     Solution I: is to have two DBs one generating even number whereas the other generating odd number. And have one load balancer route the requests
     to dbs in round-robin manner. If one db is down, the other db keeps generating number and it is possible one db has more entry than other db,
     but this will not cause any issue.

  2. How do you handle the future growth of the key, it is gonna be very large.
     Solution: We can have multiple [logical partitions] reside on a single physical database server, since each database server can have
     multiple database instances on it.  So whenever we feel that a particular database server has a lot of data, we can migrate some logical partitions from it to another server,
     and we maintain a config file maping from logic partitions to database server and update it when we move partition. This enable us move partition easier.

API 接口设计
Write(userID, image, description);
Read(userID, Last_TimeStamp, page_count); //这些参数和access token都可以在http header里传过去
不可能一次发完，feed太多了， 一次发部份，pagination的概念。第一次传入当前的timestamp, pagecount到后端要feed,
后端返回feed的同时，更新最后一个feed的timestamp, 在发给你存在broswer的cookie里。 你往下拉的时候要第二页，
http GET往后端发请求的时候，带着新发过来的timestamp，后端就从新的timestamp后面开始取，然后更新为最后一个feed的timestamp, 在发给你。
存在broswer cookie里面。

错误的做法是，传入last_feedIndex, pagecount. Example, 第一次传（0，20），读前20个，
第二次传（21，20），读后面20个。这样写的问题是，用户的feed一直在增加，同一个feed的系数会不停的变化，
这样读如果在第一次读和第二次读之间，用户的feed变化了，在feed的最前面会加入新的feed,这样就会产生错位。


</code></pre>




</body>



</html>
