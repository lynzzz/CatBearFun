<html>

<head>
   <link rel="stylesheet" type="text/css" href="../../css/utility.css">     <!-- external css file -->
</head>

<body>
<pre><code>
Goal:
Senior + compsentation
online service team using C++

Company:
Amzn（996, use to beat offer)
FB
Snapchat

Google(very few headcount/downlevel/Lowball/Need compete offer)





design:
第二题design rate limiter

设计系统允许用户rate歌曲，并检索top rated歌曲。读写分离设计。
题目大概如此，给的比较模糊，所以整个过程会跟对方确认各种细节。基本思路是确认功能集，估算资源和规模，讨论high level框架，deep dive存储层，分析如何scale和容错，讨论过程中会提到一些开源系统，解释为何选用，以及一些tradeoffs。这轮是拿coderpad做的，写设计文档..


现场SD:   设计一个计数器服务，记录所有对外提供的服务的各种活动








                                          FB:
coding: 543(ok), 42(ok), 56(ok), 297(ok), 88(ok), 23(ok), 1026(ok), 773(ok), 84(ok)
109(ok)， 938(ok), 328(ok), 896(ok), 54(0k), 157(ok), 158(ok), 20(ok), 22(ok), 301(ok), 1249(ok), 472(ok), 339(ok), 973(ok), 1197(ok), 215, 785, 1249(ok), 1428, 621(ok), 560(ok), 129(ok), 238(ok)
416(ok), 435(ok), 236(ok), (858), 1047(ok), 211(ok), 10(ok), 191(ok), 125(ok), 78(ok)， 339, 71变体(ok), 239变体(ok), 498 变体(ok) 单向右上(每一层都翻转 ok)
1123(ok)


925


                                          FB: Desgin:

Design 1:

But based on what I saw, I believe it is the web crawler problem with a large number of nodes.
As I can think, there are two ways.
1. centralized queue to distribute the workload to each node.  you have to ask the interviewer to clarify if this makes sense.
2. peer to peer network with something like NOsql/sql, depends on how strictly you allow the crawling the same url. to provide fault tolerance, I believe that you will have to allocate multiple nodes and use consistent hashing for allocating urls. when there is node failure or node addition, zookeeper like service needs to synch the new DHT/configuration to each node, so each node knows where they should send the mined urls that are not supposed to handle locally.

Design这题从之前的面经来看，大概率用message queue是不行的，也有的被要求继续design message queue。我看到的几个过经都是用的P2P DHT(Distributed hashtable)，讲一下consistent hashing，然后讲一下DHT里面比较popular的方案，Chord，KAD之类的。总之感觉几个坑题都跟P2P有关，然后Grokking没怎么讲到P2P的案例，需要自己上网找材料。



Design 2: Type Ahead


Design 3 : System Design. 先玩游戏， 然后返回leaderboard 信息包括global ranking, global top 10，friends ranking，自己的ranking 前面十个 后个十个之类的
           
           大家玩完游戏后往一个统计分数service发写请求,送分数, 然后一张DB表存 global ranking
           在用一张表存自己的前10后10.

           Requirement + capacity.

           Global ranking table: 
           User Id     pk 
           score       int 
           user Name   string
           rank        int 


           前10后10table:
           user id                 pk 
           user name               string 
           Top10Bottom10 user id   fk

           Friendship table:
           id           int  pk 
           from_user    int 
           to_user      int


           另外一个service接受读请求, 
           read global table to global ranking   (cache)  
           read global table top 10 (cache)
           从Friendship DB读好友, 从global table查分数, 排序,返回给User.
           从前10后10 table读自己的前10后10.


           partition using user id.



                                         FB: BQ
讲了最自豪的project
工作中做过什么错误的决定
onflicts with colleagues
negative feedback from manager
deal with deadlines

















                                          Twitter Coding
Coding: 380 的延伸，就是除了原题的要求，还要求getLast也是O(1)。所以要用map+doubly linked list来找getlast，map+list来找getrandom。写完了还要写unit tests，refactor code，还问有更多时间还可以做什么，比如加更多的api啊，注释啊，之类的




Design:
rate limiter.















                                      Google interview 


1）优化Web服务器实现从本地文件系统提供静态内容

2） 在围棋游戏中，如果你的周围全是棋子，将被捕获，如果你包围了自己，边界将扩大，写一个方法判断一个点是否会被捕获。

3）生成一个井字游戏的地图，包括了全部的状态和下一步的移动。规则（按序走）：如果中间为空，则赢。如果可以，击败对手，放入一个随机的地方。

4）给出了一个已知宽，高和支持的最大最小字体的屏幕，确定一个给定的字符串能显示的最大字体，单词和字符


LC 736  too hard. lisp expression





4.27 电面 巴斯斯，优化到O(1)空间复杂度  844 ?



电面: LC 流要移变形 (顺序不变) (ok 9/5)  611 ?

现场一:   尔伞巴, 咬斯巴 238(ok 9/3)   148(9/3 ok)

现场二:   无流岭, 腰尔救 560(ok 9/2) , (129 ok 9/2)

现场三(training): 腰腰救妻, 尔义伍 ( 1197)(ok 9/2)   215( priority queue ok 9/2)

现场SD:   设计一个计数器服务，记录所有对外提供的服务的各种活动
BQ:  经典题 proud project, failure experience, obstacles, feedback from previous managers


</code></pre>
</body>
